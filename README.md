# ğŸš€ Vision Pipeline Compiler

Turn a **natural language prompt** into a **runnable AI vision pipeline**.

This project converts user prompts like:

- "Detect persons and count them"
- "Segment people in an image"
- "Classify this image"
- "Pose estimation of humans"

into a **ready-to-run Python project** using **YOLOv8 pre-trained models**.

---

## ğŸ§  How It Works (High Level)

User Prompt
â†“
LLM â†’ Structured JSON
â†“
Schema Validation
â†“
Execution Plan (Compiler)
â†“
Template-Based Code Generation
â†“
Runnable AI Vision Project (ZIP)


---

## ğŸ§© Architecture Overview

### 1ï¸âƒ£ Base Template
- Loads model
- Loads input image
- Runs inference **once**
- Provides hooks for extensions

### 2ï¸âƒ£ Task Templates (Capabilities)
- Detection
- Segmentation
- Classification
- Pose Estimation

These **only interpret model results**, they never run inference again.

### 3ï¸âƒ£ Output Templates
- Bounding boxes
- Masks
- Count
- Count per class
- Classification output

These **consume prepared variables** and produce outputs.

---

## ğŸ“ Project Structure

backend/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ prompt_to_json.py
â”‚   â”œâ”€â”€ validator.py
â”‚
â”œâ”€â”€ compiler/
â”‚   â”œâ”€â”€ pipeline_builder.py
â”‚   â”œâ”€â”€ code_generator.py
â”‚   â”œâ”€â”€ task_router.py
â”‚   â”œâ”€â”€ output_resolver.py
â”‚   â”œâ”€â”€ model_resolver.py
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.py.jinja
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ detect.py.jinja
â”‚   â”‚   â”œâ”€â”€ segment.py.jinja
â”‚   â”‚   â”œâ”€â”€ classify.py.jinja
â”‚   â”‚   â””â”€â”€ pose.py.jinja
â”‚   â”œâ”€â”€ outputs/
â”‚       â”œâ”€â”€ detect.py.jinja
â”‚       â”œâ”€â”€ count.py.jinja
â”‚       â”œâ”€â”€ masks.py.jinja
â”‚       â””â”€â”€ classify.py.jinja
â”‚
â”œâ”€â”€ runtime/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ api/
    â””â”€â”€ main.py
    â””â”€â”€ routes.py
    â””â”€â”€ errors.py
    â””â”€â”€ schemas.py

---

## ğŸš€ Get Started

Follow the steps below to run the Vision Pipeline Compiler locally.

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/vision-pipeline-compiler.git
cd Prompt-to-Simple-Vision-Model
```
### 2ï¸âƒ£ Create and Activate a Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate
```
### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r runtime/requirements.txt
```

### 4ï¸âƒ£ Move to backend folder

```bash
cd backend
```

### 5ï¸âƒ£ Configure Environment Variables
Create a .env file inside the backend/ directory:
```bash
GROQ_API_KEY=your_api_key_here
```

## â–¶ï¸ Running Backend and Frontend Together

The backend and frontend run as **two separate services**.  
Open **two terminals** and start each one as shown below.

---

### ğŸ–¥ï¸ Terminal 1 â€” Backend (API)

```bash
uvicorn api.main:app --reload
```

### ğŸ–¥ï¸ Terminal 2 â€” Frontend

```bash
cd frontend
python app.py
```
